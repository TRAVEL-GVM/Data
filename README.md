# ğŸ“¦ Data Automation Repository

This repository contains the **data extraction automation infrastructure** using **GitHub Actions** to feed Streamlit applications with regularly updated data from the web.

---

## ğŸš€ Purpose

To reduce the loading time of Streamlit applications by automatically and periodically extracting external data (e.g., web scraping, APIs) and storing it in the repository.  
Each folder corresponds to an independent project with its own scripts and automation workflows.

---

## ğŸ§° Repository Structure

Data
  â”œâ”€â”€ .github/workflows/ # GitHub Actions workflows (.yml files)
  
  â”œâ”€â”€ Calibration_LDP/ # Python scripts for the LDP calibration project
  
  â”œâ”€â”€ Data/ # Folder where the extracted data files are saved
  
  â”œâ”€â”€ EMFs/ # Scripts for EMFs-related data extractions
  
  â”œâ”€â”€ MarketRisk/ # Scripts for market risk data extraction
  
  â””â”€â”€ README.md # Project documentation (this file)
  
---

## âš™ï¸ How It Works

- Each project folder (e.g., `Calibration_LDP`, `MarketRisk`) contains:
  1. Python scripts that fetch and process data from external sources
  2. Code that saves the cleaned data to the `Data/` folder

- **GitHub Actions** are configured to:
  - Automatically run these scripts on a **fixed schedule**
  - Save the updated data outputs
  - Commit the results directly to the repository

---

## ğŸ§ª Automation with GitHub Actions

The workflows defined in `.github/workflows/` handle task scheduling. Example:

```yaml
on:
  schedule:
    - cron: "0 6 * * *"  # Runs every day at 6:00 AM UTC
```

These automated jobs ensure that the data in the Data/ folder is always up to date, avoiding heavy on-demand loads in real time.

## ğŸ“Š Data Usage
Streamlit applications associated with this repository read directly from the Data/ folder, enabling fast loading and consistent access to the most recent available data.

## ğŸ“ Notes
This repository is not intended for direct analysis or visualization.

The goal is to centralize and automate the data collection process for downstream applications.

Workflow failures (e.g., due to connectivity or source changes) can be reviewed in the GitHub Actions logs.

## ğŸ‘¥ Team
This project is part of the TRAVEL-GVM initiative, focused on the automation and modernization of data processes in risk management and statistical modeling.
